{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE DE GRANDE VOLUME DE DADOS - MsC - IPT-PT\n",
    "\n",
    "## PROJETO 2\n",
    "\n",
    "### JONATAS RIBEIRO\n",
    "\n",
    "### Estratégias de Processamento de Dados em Larga Escala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "\n",
    "Leia um chunk de dados à sua escolha. Verifique quais as variáveis que beneficiariam \n",
    "de  uma  alteração  do  tipo  de  dados.  Considere  apenas  as  seguintes  colunas:  id;  year; \n",
    "month; element; value1;...;value31. Considere o valor -9999 como um NaN value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A definir os tipos de dados para as colunas específicas que serão utilizadas para a análise do dataset, em busca de otimizar o tamanho ocupado em moemória para cada chunk.\n",
    "\n",
    "\n",
    "- caregory\n",
    "- int16\n",
    "- int8\n",
    "- float32\n",
    "\n",
    "Faz sentido avaliar um pequeno segmento do dataframe, para avaliar quais as melhores opções a nível de benefício de consumo de memória em relação ao tamanho do chunk e também de transformações de dados, antes de tratarmos de grandes quantidades de dados e desperdiçar recursos valiosos de processamento e tempo.\n",
    "\n",
    "Portanto, seguindo o solicitado na task 1, abaixo estão as opções e os melhores cenários de escolha dentro das combinações possíveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = {\n",
    "    'id': 'category',\n",
    "    'year': 'int16',\n",
    "    'month': 'int8',\n",
    "    'element': 'category',\n",
    "    'value1': 'float32',\n",
    "    'value2': 'float32',\n",
    "    'value3': 'float32',\n",
    "    'value4': 'float32',\n",
    "    'value5': 'float32',\n",
    "    'value6': 'float32',\n",
    "    'value7': 'float32',\n",
    "    'value8': 'float32',\n",
    "    'value9': 'float32',\n",
    "    'value10': 'float32',\n",
    "    'value11': 'float32',\n",
    "    'value12': 'float32',\n",
    "    'value13': 'float32',\n",
    "    'value14': 'float32',\n",
    "    'value15': 'float32',\n",
    "    'value16': 'float32',\n",
    "    'value17': 'float32',\n",
    "    'value18': 'float32',\n",
    "    'value19': 'float32',\n",
    "    'value20': 'float32',\n",
    "    'value21': 'float32',\n",
    "    'value22': 'float32',\n",
    "    'value23': 'float32',\n",
    "    'value24': 'float32',\n",
    "    'value25': 'float32',\n",
    "    'value26': 'float32',\n",
    "    'value27': 'float32',\n",
    "    'value28': 'float32',\n",
    "    'value29': 'float32',\n",
    "    'value30': 'float32',\n",
    "    'value31': 'float32',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_columns =  [\n",
    "    'id', \n",
    "    'year', \n",
    "    'month', \n",
    "    'element', \n",
    "    'value1', \n",
    "    'value2', \n",
    "    'value3', \n",
    "    'value4', \n",
    "    'value5', \n",
    "    'value6', \n",
    "    'value7', \n",
    "    'value8', \n",
    "    'value9', \n",
    "    'value10', \n",
    "    'value11', \n",
    "    'value12', \n",
    "    'value13', \n",
    "    'value14', \n",
    "    'value15', \n",
    "    'value16', \n",
    "    'value17', \n",
    "    'value18', \n",
    "    'value19', \n",
    "    'value20', \n",
    "    'value21', \n",
    "    'value22', \n",
    "    'value23', \n",
    "    'value24', \n",
    "    'value25', \n",
    "    'value26', \n",
    "    'value27', \n",
    "    'value28', \n",
    "    'value29', \n",
    "    'value30', \n",
    "    'value31'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath definition\n",
    "data_path = \"data/ghcnd_daily.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, apenas a verificar o chunk sem transformação alguma, com o dataset em sua configuração original para estabelecer base de comparação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.parsers.readers.TextFileReader'>\n"
     ]
    }
   ],
   "source": [
    "# reading a single  chunks of data\n",
    "import pandas as pd\n",
    "\n",
    "chunk = pd.read_csv(data_path,chunksize=chunk_size)\n",
    "print(type(chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_15960\\564196848.py:1: DtypeWarning: Columns (6,10,14,18,22,26,30,34,38,42,46,50,54,58,62,66,70,74,78,82,86,90,94,98,102,106,110,114,118,122,126) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_chunk = chunk.get_chunk(chunk_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Columns: 128 entries, id to sflag31\n",
      "dtypes: float64(31), int64(33), object(64)\n",
      "memory usage: 153.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_chunk = chunk.get_chunk(chunk_size)\n",
    "df_chunk.head()\n",
    "df_chunk.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo avaliado as opções e os resultados obtidos, podemos então aplicar o conjunto escolhido para todo o dataset, conforme códigos seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#chunk_size definition\n",
    "chunk_size=50000\n",
    "\n",
    "#number of chunks\n",
    "batch_no=1\n",
    "\n",
    "# Modify the path to the data file\n",
    "\n",
    "for chunk in pd.read_csv(data_path, chunksize=chunk_size, usecols=chosen_columns, dtype=data_types, na_values=-9999):\n",
    "    chunk.to_csv('data/chunk'+str(batch_no)+'.csv',index=False)\n",
    "    print(batch_no)\n",
    "    batch_no+=1\n",
    "    print(chunk.head())\n",
    "    chunk.info(memory_usage=\"deep\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2 \n",
    "\n",
    "Determine a percentagem de null values em cada uma das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "\n",
    "Determine, para cada estação, o ano mais antigo e o mais recente. Hint: recorra a um \n",
    "groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n",
    "\n",
    "Determine  a  temperatura  média  para  cada  observação  (estação/ano/mês).  Guarde  os \n",
    "valores  obtidos  numa  nova  coluna  denominada  daily_avg_temp.  Não  se  esqueça  de \n",
    "considerar apenas as colunas cujo nome começa por value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5\n",
    "\n",
    "Agrupe os dados por nome de estação e ano aplicando a função mean. Mostre apenas \n",
    "os resultados para a coluna daily_avg_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6\n",
    "\n",
    "Selecione os dados 'id', 'year', 'month', 'element', 'value1', 'value2',...,'value31' das cinco \n",
    "estações meterológicas portuguesas  (Horta;  Funchal; Lisboa; Castelo Branco e Faro) \n",
    "que existem no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7\n",
    "\n",
    "Substitua os ids presentes no dataframe pelo correspondente nome da estação \n",
    "metereológica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
