{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE DE GRANDE VOLUME DE DADOS - MsC - IPT-PT\n",
    "\n",
    "## PROJETO 1\n",
    "\n",
    "### JONATAS RIBEIRO\n",
    "\n",
    "### AQUISIÇÃO, ARMAZENAMENTO E RECUPERAÇÃO DE DADOS EM LARGA ESCALA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAREFA 1 - FAMILIARIZAÇÃO COM A OBTENÇÃO DE DADOS A PARTIR DE FICHEIROS PDF\n",
    "\n",
    "- Conjunto aproximado de 100 ficheiros em PDF na pasta \"PDF_DATA_SOURCE\"\n",
    "- Tema: Sociologia Europeia\n",
    "- Modo de obtenção: web scrapping\n",
    "  - Selenium v4\n",
    "    - obtenção de 100 urls de artigos científicos na Central European University\n",
    "    - Página inicial disponibiliza apenas 20 items por vez\n",
    "    - Carregar no Botão next até o limite de 100 itens atingido\n",
    "    - Segunda parte do script é aceder a cada um dos links obtidos e realizar o download\n",
    "\n",
    "## Pré-requisitos para esta task\n",
    "\n",
    "\n",
    "\n",
    "### Extração de texto de cada ficheiro PDF\n",
    "\n",
    "### Ficheiro JSON com estrutura apropriada\n",
    "\n",
    "### Conteúdo do ficheiro JSON e nuvem de palavras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAREFA 2 - Familiarização com a obtenção de dados a partir de packages Python\n",
    "\n",
    "- A utilizar o recurso do package do wikipedia para a criação de um dataset com 2000 imagens\n",
    "- Dois temas distintos\n",
    "  - Design\n",
    "  - Restaurants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAREFA 3 - Familiarização com Web Scraping\n",
    "\n",
    "- A utilizar o recurso de web scrapping do Selenium\n",
    "- O tema principal é a obtenção de informações sobre o parlamento Europeu, nomeadamente: \n",
    "  - ùltimas notícias relevantes\n",
    "  - Próximos eventos agendados\n",
    "- Os dados são disponibilizados em uma lista final de dicionários (objetos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAREFA 4 - Familiarização com a obtenção de dados a partir de APIs\n",
    "\n",
    "- A utilizar o recurso de requisição web requests para a chamada de uma API gratuíta\n",
    "- O tema principal é relacionado as frases do famoso 'chuck norris' \n",
    "- Os dados são obtidos a cada 30 minutos\n",
    "- Uma VM foi provisionada no Microsoft Azure, para executar o script python\n",
    "- Os logs estão a ser gravados em um ficheiro a parte, para o registo do status da requisição e seu conteúdo\n",
    "- O ficheiro log é finalmente convertido para JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAREFA 5 - Familiarização com o armazenamento e recuperação de dados em larga escala \n",
    "\n",
    "- A utilizar o recurso do redis + docker\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
