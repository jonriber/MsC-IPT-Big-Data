{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid black\">\n",
    "<b><center><font size=\"4\">Big Data</font></center></b>\n",
    "\n",
    "<b><center><font size=\"3\">Big Data Strategies</font></center></b>\n",
    "\n",
    "<b><center><font size=\"2\">4 - Chunking</font></center></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook Developed by**: [Ricardo Campos](https://www.di.ubi.pt/~rcampos)<br>\n",
    "**email:**  ricardo.campos@ubi.pt<br>\n",
    "**Affiliation:** *Assistant Professor* @ [University of Beira Interior](http://www.ubi.pt);\n",
    "*Researcher* @ [LIAAD](https://www.inesctec.pt/en/centres/liaad)-[INESC TEC](https://www.inesctec.pt/en)\n",
    "\n",
    "<hr>\n",
    "<p><a href=\"4-Chunking.ipynb\" title=\"Download Notebook\" download><img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/download.jpg\" align = \"left\" width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-a-Specific-Subset\" data-toc-modified-id=\"Load-a-Specific-Subset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load a Specific Subset</a></span></li><li><span><a href=\"#Load-Multiple-Subsets\" data-toc-modified-id=\"Load-Multiple-Subsets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Multiple Subsets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Working-with-Values\" data-toc-modified-id=\"Working-with-Values-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Working with Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Unique()\" data-toc-modified-id=\"Unique()-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Unique()</a></span></li><li><span><a href=\"#Mean()\" data-toc-modified-id=\"Mean()-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Mean()</a></span></li></ul></li><li><span><a href=\"#Concatenating-Dataframes\" data-toc-modified-id=\"Concatenating-Dataframes-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Concatenating Dataframes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filter\" data-toc-modified-id=\"Filter-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Filter</a></span></li><li><span><a href=\"#GroupBy()\" data-toc-modified-id=\"GroupBy()-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>GroupBy()</a></span></li></ul></li><li><span><a href=\"#Operations-Resulting-in-a-Series\" data-toc-modified-id=\"Operations-Resulting-in-a-Series-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Operations Resulting in a Series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Count-Null-Values\" data-toc-modified-id=\"Count-Null-Values-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Count Null Values</a></span></li><li><span><a href=\"#Value_Counts()\" data-toc-modified-id=\"Value_Counts()-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Value_Counts()</a></span></li><li><span><a href=\"#Groupby()\" data-toc-modified-id=\"Groupby()-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Groupby()</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Objetivos de aprendizagem  <a class=\"tocSkip\">\n",
    "    \n",
    "No final deste notebook o aluno deverá saber efetuar chunking como forma de processar elevados volumes de dados.\n",
    "\n",
    "\n",
    "## Learning Objectives  <a class=\"tocSkip\">\n",
    "       \n",
    "When concluding this notebook, the student should know how to perform chunking to handle big data files.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "\n",
    "## Sumário  <a class=\"tocSkip\">\n",
    "### Técnicas de Compressão<a class=\"tocSkip\">\n",
    "\n",
    "Introdução dos alunos ao chunking de elevados volumes de dados\n",
    "    \n",
    "## Class Summary  <a class=\"tocSkip\">\n",
    "### Compression Techniques <a class=\"tocSkip\">\n",
    "Introducing students to the process of chunking big data files\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte desta seção teve por base o seguinte artigo: https://towardsdatascience.com/loading-large-datasets-in-pandas-11bdddd36f7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a Specific Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de lidar com os problemas colocados pela leitura de datasets de considerável tamanho, passa por recorrer ao chunking, um processo que divide um dataset num conjunto de sub-datasets mais pequenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outras palavras, em vez de ler todos os dados de uma vez na memória, podemos dividir em partes ou blocos menores. No caso de ficheiros CSV, isso significaria carregar apenas algumas linhas em memória num determinado momento. A função `read_csv ()` do Pandas vem com um parâmetro `chunksize` que permite definir o tamanho do chunking. No código seguinte escolhemos um chunk_size de 50.000, o que significa que vamos carregar em memória apenas as top-50.000 linhas de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is the `yellow_tripdata`  which can be found here: https://www.kaggle.com/datasets/bharath150/taxi-data?select=yellow_tripdata_2016-03.csv. Yellow taxi trip records include fields capturing pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, rate types, payment types, and driver-reported passenger counts. The data used in the attached datasets were collected and provided to the NYC Taxi and Limousine Commission (TLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.io.parsers.readers.TextFileReader'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=50000\n",
    "chunk = pd.read_csv('data\\yellow_tripdata_2016-03.csv',chunksize=chunk_size)\n",
    "#chunk = pd.read_csv('f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv',chunksize=chunk_size)\n",
    "print(type(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida recorremos ao `get_chunk` para ter acesso ao respetivo dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:07:55</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-73.976746</td>\n",
       "      <td>40.765152</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.004265</td>\n",
       "      <td>40.746128</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:11:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-73.983482</td>\n",
       "      <td>40.767925</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.005943</td>\n",
       "      <td>40.733166</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:31:06</td>\n",
       "      <td>2</td>\n",
       "      <td>19.98</td>\n",
       "      <td>-73.782021</td>\n",
       "      <td>40.644810</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.974541</td>\n",
       "      <td>40.675770</td>\n",
       "      <td>1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10.78</td>\n",
       "      <td>-73.863419</td>\n",
       "      <td>40.769814</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.969650</td>\n",
       "      <td>40.757767</td>\n",
       "      <td>1</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.3</td>\n",
       "      <td>41.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>30.43</td>\n",
       "      <td>-73.971741</td>\n",
       "      <td>40.792183</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.177170</td>\n",
       "      <td>40.695053</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>113.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2016-03-01 00:00:00   2016-03-01 00:07:55                1   \n",
       "1         1  2016-03-01 00:00:00   2016-03-01 00:11:06                1   \n",
       "2         2  2016-03-01 00:00:00   2016-03-01 00:31:06                2   \n",
       "3         2  2016-03-01 00:00:00   2016-03-01 00:00:00                3   \n",
       "4         2  2016-03-01 00:00:00   2016-03-01 00:00:00                5   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
       "0           2.50        -73.976746        40.765152           1   \n",
       "1           2.90        -73.983482        40.767925           1   \n",
       "2          19.98        -73.782021        40.644810           1   \n",
       "3          10.78        -73.863419        40.769814           1   \n",
       "4          30.43        -73.971741        40.792183           3   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
       "0                  N         -74.004265         40.746128             1   \n",
       "1                  N         -74.005943         40.733166             1   \n",
       "2                  N         -73.974541         40.675770             1   \n",
       "3                  N         -73.969650         40.757767             1   \n",
       "4                  N         -74.177170         40.695053             1   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0          9.0    0.5      0.5        2.05          0.00   \n",
       "1         11.0    0.5      0.5        3.05          0.00   \n",
       "2         54.5    0.5      0.5        8.00          0.00   \n",
       "3         31.5    0.0      0.5        3.78          5.54   \n",
       "4         98.0    0.0      0.0        0.00         15.50   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3         12.35  \n",
       "1                    0.3         15.35  \n",
       "2                    0.3         63.80  \n",
       "3                    0.3         41.62  \n",
       "4                    0.3        113.80  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk = chunk.get_chunk(chunk_size)\n",
    "df_chunk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente a quantidade de memória usada pelo dataframe deste chunk em particular (e porque se tratam apenas de 50,000 linhas) é agora muito menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   VendorID               50000 non-null  int64  \n",
      " 1   tpep_pickup_datetime   50000 non-null  object \n",
      " 2   tpep_dropoff_datetime  50000 non-null  object \n",
      " 3   passenger_count        50000 non-null  int64  \n",
      " 4   trip_distance          50000 non-null  float64\n",
      " 5   pickup_longitude       50000 non-null  float64\n",
      " 6   pickup_latitude        50000 non-null  float64\n",
      " 7   RatecodeID             50000 non-null  int64  \n",
      " 8   store_and_fwd_flag     50000 non-null  object \n",
      " 9   dropoff_longitude      50000 non-null  float64\n",
      " 10  dropoff_latitude       50000 non-null  float64\n",
      " 11  payment_type           50000 non-null  int64  \n",
      " 12  fare_amount            50000 non-null  float64\n",
      " 13  extra                  50000 non-null  float64\n",
      " 14  mta_tax                50000 non-null  float64\n",
      " 15  tip_amount             50000 non-null  float64\n",
      " 16  tolls_amount           50000 non-null  float64\n",
      " 17  improvement_surcharge  50000 non-null  float64\n",
      " 18  total_amount           50000 non-null  float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 16.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_chunk.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A importação de um pequeno segmento do dataframe (em linha com o aprendido em notebooks anteriores, nomeadamente através do parâmetro skiprows ou do recurso a bases de dados e queries sql) possibilita a execução de um conjunto de operações e uma análise preliminar do dataframe, sem comprometer a rapidez das operações (dada a reduzida dimensão do dataset). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos por exemplo beneficiar da informação anterior para tomar decisões relativamente à seleção de um conjunto restrito de colunas, ou transformação de dados (de object para datetime, através do parâmetro `parse_date`; de int64 para int16, etc, através do parâmetro `dtype`) e avaliar o seu impacto em termos de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               50000 non-null  int16         \n",
      " 1   tpep_pickup_datetime   50000 non-null  datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  50000 non-null  datetime64[ns]\n",
      " 3   passenger_count        50000 non-null  int8          \n",
      " 4   trip_distance          50000 non-null  float32       \n",
      " 5   payment_type           50000 non-null  int8          \n",
      " 6   fare_amount            50000 non-null  float32       \n",
      " 7   tip_amount             50000 non-null  float32       \n",
      " 8   tolls_amount           50000 non-null  float32       \n",
      " 9   total_amount           50000 non-null  float32       \n",
      "dtypes: datetime64[ns](2), float32(5), int16(1), int8(2)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=50000\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "path = \"data\\yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "chunk = pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"})\n",
    "\n",
    "df_chunk = chunk.get_chunk(chunk_size)\n",
    "df_chunk.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliadas as consequências destas opções poderíamos então aplicá-las a todo o dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Multiple Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra possibilidade passa por recorrer ao chunking para dividir e guardar os chunks em múltiplos ficheiros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/BigData/chunking.jpg\" width=\"300\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Source: https://towardsdatascience.com/loading-large-datasets-in-pandas-11bdddd36f7b</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No código seguinte escolhemos um chunk_size de 50.000, o que significa que cada novo ficheiro chunk a ser gerado incluirá apenas 50.000 linhas de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=50000\n",
    "batch_no=1\n",
    "\n",
    "for chunk_df in pd.read_csv('data/yellow_tripdata_2016-03.csv',chunksize=chunk_size):\n",
    "# for chunk_df in pd.read_csv('f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv',chunksize=chunk_size):\n",
    "    # chunk_df.to_csv('f:/O meu disco/data/BigData/yellow_taxi_data/data/chunk'+str(batch_no)+'.csv',index=False)\n",
    "    chunk_df.to_csv('data/chunk'+str(batch_no)+'.csv',index=False)\n",
    "    print(batch_no)\n",
    "    batch_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada chunk é na verdade um dataframe (chunk_df)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A importação de um chunk em específico faz-se depois a partir do seguinte código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:07:55</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-73.976746</td>\n",
       "      <td>40.765152</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.004265</td>\n",
       "      <td>40.746128</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:11:06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-73.983482</td>\n",
       "      <td>40.767925</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.005943</td>\n",
       "      <td>40.733166</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:31:06</td>\n",
       "      <td>2</td>\n",
       "      <td>19.98</td>\n",
       "      <td>-73.782021</td>\n",
       "      <td>40.644810</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.974541</td>\n",
       "      <td>40.675770</td>\n",
       "      <td>1</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10.78</td>\n",
       "      <td>-73.863419</td>\n",
       "      <td>40.769814</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>-73.969650</td>\n",
       "      <td>40.757767</td>\n",
       "      <td>1</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.3</td>\n",
       "      <td>41.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>2016-03-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>30.43</td>\n",
       "      <td>-73.971741</td>\n",
       "      <td>40.792183</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>-74.177170</td>\n",
       "      <td>40.695053</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>113.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2016-03-01 00:00:00   2016-03-01 00:07:55                1   \n",
       "1         1  2016-03-01 00:00:00   2016-03-01 00:11:06                1   \n",
       "2         2  2016-03-01 00:00:00   2016-03-01 00:31:06                2   \n",
       "3         2  2016-03-01 00:00:00   2016-03-01 00:00:00                3   \n",
       "4         2  2016-03-01 00:00:00   2016-03-01 00:00:00                5   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
       "0           2.50        -73.976746        40.765152           1   \n",
       "1           2.90        -73.983482        40.767925           1   \n",
       "2          19.98        -73.782021        40.644810           1   \n",
       "3          10.78        -73.863419        40.769814           1   \n",
       "4          30.43        -73.971741        40.792183           3   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude  payment_type  \\\n",
       "0                  N         -74.004265         40.746128             1   \n",
       "1                  N         -74.005943         40.733166             1   \n",
       "2                  N         -73.974541         40.675770             1   \n",
       "3                  N         -73.969650         40.757767             1   \n",
       "4                  N         -74.177170         40.695053             1   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0          9.0    0.5      0.5        2.05          0.00   \n",
       "1         11.0    0.5      0.5        3.05          0.00   \n",
       "2         54.5    0.5      0.5        8.00          0.00   \n",
       "3         31.5    0.0      0.5        3.78          5.54   \n",
       "4         98.0    0.0      0.0        0.00         15.50   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3         12.35  \n",
       "1                    0.3         15.35  \n",
       "2                    0.3         63.80  \n",
       "3                    0.3         41.62  \n",
       "4                    0.3        113.80  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = \"f:/O meu disco/data/BigData/yellow_taxi_data/data/chunk1.csv\"\n",
    "path = \"data/chunk1.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturalmente a quantidade de memória usada pelo dataframe deste chunk em particular (e porque se tratam apenas de 50,000 linhas) é agora muito menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   VendorID               50000 non-null  int64  \n",
      " 1   tpep_pickup_datetime   50000 non-null  object \n",
      " 2   tpep_dropoff_datetime  50000 non-null  object \n",
      " 3   passenger_count        50000 non-null  int64  \n",
      " 4   trip_distance          50000 non-null  float64\n",
      " 5   pickup_longitude       50000 non-null  float64\n",
      " 6   pickup_latitude        50000 non-null  float64\n",
      " 7   RatecodeID             50000 non-null  int64  \n",
      " 8   store_and_fwd_flag     50000 non-null  object \n",
      " 9   dropoff_longitude      50000 non-null  float64\n",
      " 10  dropoff_latitude       50000 non-null  float64\n",
      " 11  payment_type           50000 non-null  int64  \n",
      " 12  fare_amount            50000 non-null  float64\n",
      " 13  extra                  50000 non-null  float64\n",
      " 14  mta_tax                50000 non-null  float64\n",
      " 15  tip_amount             50000 non-null  float64\n",
      " 16  tolls_amount           50000 non-null  float64\n",
      " 17  improvement_surcharge  50000 non-null  float64\n",
      " 18  total_amount           50000 non-null  float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 16.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A divisão do dataset em múltiplos datasets permitiria agora não só a sua exploração sob o ponto de vista de uma análise preliminar (a partir do load de um dataset em específico), mas também a execução de uma série de operações nos vários datasets. Tal procedimento não obriga no entanto a guardar dos vários subsets. De facto podemos proceder à divisão do mesmos por intermédio do chunking, efetuar as necessárias operações, e reunir os resultados num único dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figura seguinte exemplifica este processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.di.ubi.pt/~rcampos/assets/img_tutorials/BigData/chunking1.jpg\" width=\"800\" height=\"800\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>https://www.aiplusinfo.com/blog/pandas-and-large-dataframes-how-to-read-in-chunks/</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo seguinte enviamos para uma lista o número total de `passenger_count` (i.e., de passageiros transportados nas viagens) em cada chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "ListOfResults = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "# path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df['passenger_count'].unique()\n",
    "    ListOfResults.extend(chunk_result)\n",
    "        \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente convertemos a lista para um set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ListOfResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo seguinte determinamos a média do campo `fare_amount` para cada chunk, adicionando-a respetivamente a cada posição da lista de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.582056"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk[\"fare_amount\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "ListOfResults = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "# path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df['fare_amount'].mean()\n",
    "    ListOfResults.append(chunk_result)\n",
    "        \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ListOfResults` é assim uma lista com todas as médias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.643791,\n",
       " 12.337623,\n",
       " 12.632169,\n",
       " 12.307339,\n",
       " 12.246566,\n",
       " 13.048718,\n",
       " 12.895504,\n",
       " 12.843733,\n",
       " 12.817127,\n",
       " 12.90739,\n",
       " 13.406391,\n",
       " 13.040576,\n",
       " 12.280393,\n",
       " 13.194853,\n",
       " 12.762296,\n",
       " 12.910908,\n",
       " 12.741346,\n",
       " 13.678961,\n",
       " 12.665683,\n",
       " 12.869327,\n",
       " 12.121111,\n",
       " 12.94458,\n",
       " 12.609477,\n",
       " 12.998912,\n",
       " 13.2148905]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListOfResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para termos acesso à média deveremos proceder ao seguinte cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.804786491394044"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ListOfResults)/len(ListOfResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos começar por exemplificar este processo com recurso a operações de filtro, as quais têm por objetivo selecionar apenas umas quantas observações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte (**uma solução melhor que esta encontra-se mais abaixo nesta seção**) permite dividir o dataset em parcelas de `500,000` linhas e em cada uma dessas parcelas aplicar um filtro que seleciona apenas os registos onde `passenger_count = 4`. O conjunto desses registos é concatenado ao dataframe anterior a cada nova iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_17484\\1714829958.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, chunk_result])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "df = pd.DataFrame(columns = column_names) #define the df with the header\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df[chunk_df['passenger_count']==4]\n",
    "\n",
    "    df = pd.concat([df, chunk_result])\n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:08</td>\n",
       "      <td>2016-03-01 00:16:31</td>\n",
       "      <td>4</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:27</td>\n",
       "      <td>2016-03-01 00:07:37</td>\n",
       "      <td>4</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:49</td>\n",
       "      <td>2016-03-01 00:13:29</td>\n",
       "      <td>4</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:01:03</td>\n",
       "      <td>2016-03-01 00:07:10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-10 07:07:40</td>\n",
       "      <td>2016-03-10 07:13:55</td>\n",
       "      <td>4</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210793</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31 23:59:30</td>\n",
       "      <td>2016-04-01 00:21:53</td>\n",
       "      <td>4</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210885</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31 23:59:49</td>\n",
       "      <td>2016-04-01 00:27:36</td>\n",
       "      <td>4</td>\n",
       "      <td>10.340000</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210936</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-29 16:46:55</td>\n",
       "      <td>2016-03-29 16:49:21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>62.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210942</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-30 13:41:39</td>\n",
       "      <td>2016-03-30 15:04:46</td>\n",
       "      <td>4</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>58.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210944</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-31 21:43:11</td>\n",
       "      <td>2016-03-31 22:29:27</td>\n",
       "      <td>4</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239827 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime passenger_count  \\\n",
       "31              2  2016-03-01 00:00:08   2016-03-01 00:16:31               4   \n",
       "78              2  2016-03-01 00:00:27   2016-03-01 00:07:37               4   \n",
       "136             1  2016-03-01 00:00:49   2016-03-01 00:13:29               4   \n",
       "164             2  2016-03-01 00:01:03   2016-03-01 00:07:10               4   \n",
       "233             2  2016-03-10 07:07:40   2016-03-10 07:13:55               4   \n",
       "...           ...                  ...                   ...             ...   \n",
       "12210793        2  2016-03-31 23:59:30   2016-04-01 00:21:53               4   \n",
       "12210885        2  2016-03-31 23:59:49   2016-04-01 00:27:36               4   \n",
       "12210936        1  2016-03-29 16:46:55   2016-03-29 16:49:21               4   \n",
       "12210942        1  2016-03-30 13:41:39   2016-03-30 15:04:46               4   \n",
       "12210944        1  2016-03-31 21:43:11   2016-03-31 22:29:27               4   \n",
       "\n",
       "          trip_distance payment_type  fare_amount  tip_amount  tolls_amount  \\\n",
       "31             4.260000            2         16.0        0.00          0.00   \n",
       "78             1.040000            1          6.5        1.56          0.00   \n",
       "136            2.500000            1         11.0        3.07          0.00   \n",
       "164            1.650000            1          7.0        1.66          0.00   \n",
       "233            2.050000            1          7.5        1.66          0.00   \n",
       "...                 ...          ...          ...         ...           ...   \n",
       "12210793       5.680000            2         20.0        0.00          0.00   \n",
       "12210885      10.340000            1         31.0        6.46          0.00   \n",
       "12210936       0.400000            2         52.0        0.00          5.54   \n",
       "12210942      17.799999            2         52.0        0.00          5.54   \n",
       "12210944      18.900000            2         57.5        0.00          0.00   \n",
       "\n",
       "          total_amount  \n",
       "31           17.299999  \n",
       "78            9.360000  \n",
       "136          15.370000  \n",
       "164           9.960000  \n",
       "233           9.960000  \n",
       "...                ...  \n",
       "12210793     21.299999  \n",
       "12210885     38.759998  \n",
       "12210936     62.840000  \n",
       "12210942     58.340000  \n",
       "12210944     58.799999  \n",
       "\n",
       "[239827 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que ocupa apenas 32.5MB de memória RAM ao invés dos iniciais 3.8GB (que o dataset ocupa quando carregado na totalidade em memória)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 239827 entries, 31 to 12210944\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   VendorID               239827 non-null  object        \n",
      " 1   tpep_pickup_datetime   239827 non-null  datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  239827 non-null  datetime64[ns]\n",
      " 3   passenger_count        239827 non-null  object        \n",
      " 4   trip_distance          239827 non-null  float32       \n",
      " 5   payment_type           239827 non-null  object        \n",
      " 6   fare_amount            239827 non-null  float32       \n",
      " 7   tip_amount             239827 non-null  float32       \n",
      " 8   tolls_amount           239827 non-null  float32       \n",
      " 9   total_amount           239827 non-null  float32       \n",
      "dtypes: datetime64[ns](2), float32(5), object(3)\n",
      "memory usage: 34.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is better to append the aggregated data to a list, and then build the DataFrame from the list with one call to pd.concat which is a O(N) operation (where N is the size of the chunks). That is, it is better to concat once with a list of many dataframes `pd.concat([list_of_dfs])` instead of doing something like `df = pd.concat([df, chunk])` many times in a for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cope with this, we define a `result_temp` list which will get all the chunk dataframes `chunk_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:08</td>\n",
       "      <td>2016-03-01 00:16:31</td>\n",
       "      <td>4</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:00:27</td>\n",
       "      <td>2016-03-01 00:07:37</td>\n",
       "      <td>4</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-01 00:00:49</td>\n",
       "      <td>2016-03-01 00:13:29</td>\n",
       "      <td>4</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-01 00:01:03</td>\n",
       "      <td>2016-03-01 00:07:10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-10 07:07:40</td>\n",
       "      <td>2016-03-10 07:13:55</td>\n",
       "      <td>4</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210793</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31 23:59:30</td>\n",
       "      <td>2016-04-01 00:21:53</td>\n",
       "      <td>4</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210885</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31 23:59:49</td>\n",
       "      <td>2016-04-01 00:27:36</td>\n",
       "      <td>4</td>\n",
       "      <td>10.340000</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210936</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-29 16:46:55</td>\n",
       "      <td>2016-03-29 16:49:21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>62.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210942</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-30 13:41:39</td>\n",
       "      <td>2016-03-30 15:04:46</td>\n",
       "      <td>4</td>\n",
       "      <td>17.799999</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>58.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12210944</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-03-31 21:43:11</td>\n",
       "      <td>2016-03-31 22:29:27</td>\n",
       "      <td>4</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239827 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "31               2  2016-03-01 00:00:08   2016-03-01 00:16:31   \n",
       "78               2  2016-03-01 00:00:27   2016-03-01 00:07:37   \n",
       "136              1  2016-03-01 00:00:49   2016-03-01 00:13:29   \n",
       "164              2  2016-03-01 00:01:03   2016-03-01 00:07:10   \n",
       "233              2  2016-03-10 07:07:40   2016-03-10 07:13:55   \n",
       "...            ...                  ...                   ...   \n",
       "12210793         2  2016-03-31 23:59:30   2016-04-01 00:21:53   \n",
       "12210885         2  2016-03-31 23:59:49   2016-04-01 00:27:36   \n",
       "12210936         1  2016-03-29 16:46:55   2016-03-29 16:49:21   \n",
       "12210942         1  2016-03-30 13:41:39   2016-03-30 15:04:46   \n",
       "12210944         1  2016-03-31 21:43:11   2016-03-31 22:29:27   \n",
       "\n",
       "          passenger_count  trip_distance  payment_type  fare_amount  \\\n",
       "31                      4       4.260000             2         16.0   \n",
       "78                      4       1.040000             1          6.5   \n",
       "136                     4       2.500000             1         11.0   \n",
       "164                     4       1.650000             1          7.0   \n",
       "233                     4       2.050000             1          7.5   \n",
       "...                   ...            ...           ...          ...   \n",
       "12210793                4       5.680000             2         20.0   \n",
       "12210885                4      10.340000             1         31.0   \n",
       "12210936                4       0.400000             2         52.0   \n",
       "12210942                4      17.799999             2         52.0   \n",
       "12210944                4      18.900000             2         57.5   \n",
       "\n",
       "          tip_amount  tolls_amount  total_amount  \n",
       "31              0.00          0.00     17.299999  \n",
       "78              1.56          0.00      9.360000  \n",
       "136             3.07          0.00     15.370000  \n",
       "164             1.66          0.00      9.960000  \n",
       "233             1.66          0.00      9.960000  \n",
       "...              ...           ...           ...  \n",
       "12210793        0.00          0.00     21.299999  \n",
       "12210885        6.46          0.00     38.759998  \n",
       "12210936        0.00          5.54     62.840000  \n",
       "12210942        0.00          5.54     58.340000  \n",
       "12210944        0.00          0.00     58.799999  \n",
       "\n",
       "[239827 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "result_temp = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df[chunk_df['passenger_count']==4]\n",
    "\n",
    "    result_temp.append(chunk_result)\n",
    "    \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1\n",
    "\n",
    "df = pd.concat(result_temp)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is likely not only quicker, but also occupies less memory, only `11MB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 239827 entries, 31 to 12210944\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   VendorID               239827 non-null  int16         \n",
      " 1   tpep_pickup_datetime   239827 non-null  datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  239827 non-null  datetime64[ns]\n",
      " 3   passenger_count        239827 non-null  int8          \n",
      " 4   trip_distance          239827 non-null  float32       \n",
      " 5   payment_type           239827 non-null  int8          \n",
      " 6   fare_amount            239827 non-null  float32       \n",
      " 7   tip_amount             239827 non-null  float32       \n",
      " 8   tolls_amount           239827 non-null  float32       \n",
      " 9   total_amount           239827 non-null  float32       \n",
      "dtypes: datetime64[ns](2), float32(5), int16(1), int8(2)\n",
      "memory usage: 11.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um outro exemplo prende-se com a lista de todas as observações NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, payment_type, fare_amount, tip_amount, tolls_amount, total_amount]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "result_temp = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df[chunk_df.isnull().any(axis=1)]\n",
    "\n",
    "    result_temp.append(chunk_result)\n",
    "    \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1\n",
    "\n",
    "df = pd.concat(result_temp)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As operações de groupby quando restritas a mais do que uma coluna devolvem o resultado num dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "result_temp = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df.groupby('VendorID').mean()[['trip_distance','fare_amount','tip_amount','tolls_amount','total_amount']]\n",
    "\n",
    "    result_temp.append(chunk_result)\n",
    "    \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1\n",
    "\n",
    "df = pd.concat(result_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar abaixo, temos agora um conjunto de groupbys para cada chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.395535</td>\n",
       "      <td>12.321449</td>\n",
       "      <td>1.788088</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>15.597042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.921303</td>\n",
       "      <td>12.838291</td>\n",
       "      <td>1.876879</td>\n",
       "      <td>0.341641</td>\n",
       "      <td>16.158247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.676330</td>\n",
       "      <td>12.170998</td>\n",
       "      <td>1.799639</td>\n",
       "      <td>0.277599</td>\n",
       "      <td>15.375791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.802897</td>\n",
       "      <td>12.479285</td>\n",
       "      <td>1.868774</td>\n",
       "      <td>0.303754</td>\n",
       "      <td>15.813581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.756580</td>\n",
       "      <td>12.519168</td>\n",
       "      <td>1.832608</td>\n",
       "      <td>0.300477</td>\n",
       "      <td>15.800862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.862911</td>\n",
       "      <td>12.730000</td>\n",
       "      <td>1.882542</td>\n",
       "      <td>0.320997</td>\n",
       "      <td>16.102346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.806111</td>\n",
       "      <td>12.217259</td>\n",
       "      <td>1.693334</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>15.341509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.870971</td>\n",
       "      <td>12.385400</td>\n",
       "      <td>1.732976</td>\n",
       "      <td>0.259027</td>\n",
       "      <td>15.578025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.799309</td>\n",
       "      <td>12.110503</td>\n",
       "      <td>1.597721</td>\n",
       "      <td>0.223734</td>\n",
       "      <td>14.953568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.905119</td>\n",
       "      <td>12.359179</td>\n",
       "      <td>1.662298</td>\n",
       "      <td>0.245710</td>\n",
       "      <td>15.324739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.244994</td>\n",
       "      <td>13.124643</td>\n",
       "      <td>1.853899</td>\n",
       "      <td>0.384581</td>\n",
       "      <td>16.446419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.123266</td>\n",
       "      <td>13.037733</td>\n",
       "      <td>1.858980</td>\n",
       "      <td>0.323531</td>\n",
       "      <td>16.370035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.152014</td>\n",
       "      <td>12.700207</td>\n",
       "      <td>1.849901</td>\n",
       "      <td>0.327427</td>\n",
       "      <td>15.902591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.135735</td>\n",
       "      <td>12.919114</td>\n",
       "      <td>1.757677</td>\n",
       "      <td>0.317230</td>\n",
       "      <td>15.972290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.531933</td>\n",
       "      <td>12.269436</td>\n",
       "      <td>1.708807</td>\n",
       "      <td>0.281047</td>\n",
       "      <td>15.057683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.945799</td>\n",
       "      <td>12.855990</td>\n",
       "      <td>1.891595</td>\n",
       "      <td>0.358212</td>\n",
       "      <td>16.295074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.975181</td>\n",
       "      <td>12.552181</td>\n",
       "      <td>1.710649</td>\n",
       "      <td>0.366381</td>\n",
       "      <td>15.613980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.007746</td>\n",
       "      <td>12.989585</td>\n",
       "      <td>1.853293</td>\n",
       "      <td>0.371593</td>\n",
       "      <td>16.303904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.235002</td>\n",
       "      <td>12.769554</td>\n",
       "      <td>1.855600</td>\n",
       "      <td>0.325328</td>\n",
       "      <td>16.245964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.942349</td>\n",
       "      <td>13.028803</td>\n",
       "      <td>1.927502</td>\n",
       "      <td>0.347754</td>\n",
       "      <td>16.613104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.407313</td>\n",
       "      <td>13.278633</td>\n",
       "      <td>1.929356</td>\n",
       "      <td>0.337651</td>\n",
       "      <td>16.765541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.162585</td>\n",
       "      <td>13.517856</td>\n",
       "      <td>1.981485</td>\n",
       "      <td>0.353079</td>\n",
       "      <td>17.072683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.954083</td>\n",
       "      <td>12.956741</td>\n",
       "      <td>1.801036</td>\n",
       "      <td>0.299385</td>\n",
       "      <td>16.260696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.041197</td>\n",
       "      <td>13.115983</td>\n",
       "      <td>1.833238</td>\n",
       "      <td>0.309704</td>\n",
       "      <td>16.468678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.161613</td>\n",
       "      <td>12.198803</td>\n",
       "      <td>1.601393</td>\n",
       "      <td>0.235485</td>\n",
       "      <td>15.040366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.934990</td>\n",
       "      <td>12.352533</td>\n",
       "      <td>1.623512</td>\n",
       "      <td>0.245195</td>\n",
       "      <td>15.208194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.426266</td>\n",
       "      <td>13.603872</td>\n",
       "      <td>1.730418</td>\n",
       "      <td>0.366990</td>\n",
       "      <td>16.727602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.144284</td>\n",
       "      <td>12.831040</td>\n",
       "      <td>1.801288</td>\n",
       "      <td>0.399269</td>\n",
       "      <td>16.044466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.846411</td>\n",
       "      <td>12.593754</td>\n",
       "      <td>1.769177</td>\n",
       "      <td>0.339073</td>\n",
       "      <td>15.958479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.000887</td>\n",
       "      <td>12.910982</td>\n",
       "      <td>1.843805</td>\n",
       "      <td>0.366249</td>\n",
       "      <td>16.397614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.921319</td>\n",
       "      <td>12.783735</td>\n",
       "      <td>1.850048</td>\n",
       "      <td>0.293639</td>\n",
       "      <td>16.171896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.038696</td>\n",
       "      <td>13.022623</td>\n",
       "      <td>1.908270</td>\n",
       "      <td>0.316655</td>\n",
       "      <td>16.496910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.331852</td>\n",
       "      <td>12.654902</td>\n",
       "      <td>1.785889</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>15.876081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.939575</td>\n",
       "      <td>13.047328</td>\n",
       "      <td>1.812695</td>\n",
       "      <td>0.354567</td>\n",
       "      <td>16.140940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.931685</td>\n",
       "      <td>13.695339</td>\n",
       "      <td>1.888933</td>\n",
       "      <td>0.325784</td>\n",
       "      <td>17.091923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.905485</td>\n",
       "      <td>12.825491</td>\n",
       "      <td>1.887194</td>\n",
       "      <td>0.337151</td>\n",
       "      <td>16.464405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.470058</td>\n",
       "      <td>12.600686</td>\n",
       "      <td>1.690859</td>\n",
       "      <td>0.275816</td>\n",
       "      <td>15.665549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.234261</td>\n",
       "      <td>14.885476</td>\n",
       "      <td>2.046081</td>\n",
       "      <td>0.574831</td>\n",
       "      <td>18.865957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.097044</td>\n",
       "      <td>12.835858</td>\n",
       "      <td>1.779412</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>16.188978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.113313</td>\n",
       "      <td>12.904242</td>\n",
       "      <td>1.806452</td>\n",
       "      <td>0.287527</td>\n",
       "      <td>16.304647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.560074</td>\n",
       "      <td>12.060934</td>\n",
       "      <td>1.467850</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>14.746906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.935695</td>\n",
       "      <td>12.173380</td>\n",
       "      <td>1.488147</td>\n",
       "      <td>0.210860</td>\n",
       "      <td>14.870617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.331007</td>\n",
       "      <td>12.717742</td>\n",
       "      <td>1.658917</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>15.831400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.228000</td>\n",
       "      <td>13.144399</td>\n",
       "      <td>1.763345</td>\n",
       "      <td>0.414917</td>\n",
       "      <td>16.394499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.145880</td>\n",
       "      <td>12.476356</td>\n",
       "      <td>1.775733</td>\n",
       "      <td>0.307031</td>\n",
       "      <td>15.733659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.049400</td>\n",
       "      <td>12.726954</td>\n",
       "      <td>1.831512</td>\n",
       "      <td>0.330712</td>\n",
       "      <td>16.070793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.909785</td>\n",
       "      <td>12.890533</td>\n",
       "      <td>1.817403</td>\n",
       "      <td>0.313974</td>\n",
       "      <td>16.128195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.915018</td>\n",
       "      <td>13.094385</td>\n",
       "      <td>1.874219</td>\n",
       "      <td>0.337107</td>\n",
       "      <td>16.412281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.941266</td>\n",
       "      <td>13.073690</td>\n",
       "      <td>1.914098</td>\n",
       "      <td>0.322338</td>\n",
       "      <td>16.771259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.069315</td>\n",
       "      <td>13.340336</td>\n",
       "      <td>1.968144</td>\n",
       "      <td>0.334315</td>\n",
       "      <td>17.109434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trip_distance  fare_amount  tip_amount  tolls_amount  total_amount\n",
       "VendorID                                                                    \n",
       "1             29.395535    12.321449    1.788088      0.293510     15.597042\n",
       "2              2.921303    12.838291    1.876879      0.341641     16.158247\n",
       "1              2.676330    12.170998    1.799639      0.277599     15.375791\n",
       "2              2.802897    12.479285    1.868774      0.303754     15.813581\n",
       "1              2.756580    12.519168    1.832608      0.300477     15.800862\n",
       "2              2.862911    12.730000    1.882542      0.320997     16.102346\n",
       "1              2.806111    12.217259    1.693334      0.245700     15.341509\n",
       "2              2.870971    12.385400    1.732976      0.259027     15.578025\n",
       "1              2.799309    12.110503    1.597721      0.223734     14.953568\n",
       "2              2.905119    12.359179    1.662298      0.245710     15.324739\n",
       "1              3.244994    13.124643    1.853899      0.384581     16.446419\n",
       "2              3.123266    13.037733    1.858980      0.323531     16.370035\n",
       "1              3.152014    12.700207    1.849901      0.327427     15.902591\n",
       "2              3.135735    12.919114    1.757677      0.317230     15.972290\n",
       "1              2.531933    12.269436    1.708807      0.281047     15.057683\n",
       "2              2.945799    12.855990    1.891595      0.358212     16.295074\n",
       "1             14.975181    12.552181    1.710649      0.366381     15.613980\n",
       "2              3.007746    12.989585    1.853293      0.371593     16.303904\n",
       "1              6.235002    12.769554    1.855600      0.325328     16.245964\n",
       "2              2.942349    13.028803    1.927502      0.347754     16.613104\n",
       "1              4.407313    13.278633    1.929356      0.337651     16.765541\n",
       "2              3.162585    13.517856    1.981485      0.353079     17.072683\n",
       "1              2.954083    12.956741    1.801036      0.299385     16.260696\n",
       "2              3.041197    13.115983    1.833238      0.309704     16.468678\n",
       "1              4.161613    12.198803    1.601393      0.235485     15.040366\n",
       "2              2.934990    12.352533    1.623512      0.245195     15.208194\n",
       "1              6.426266    13.603872    1.730418      0.366990     16.727602\n",
       "2              3.144284    12.831040    1.801288      0.399269     16.044466\n",
       "1              2.846411    12.593754    1.769177      0.339073     15.958479\n",
       "2              3.000887    12.910982    1.843805      0.366249     16.397614\n",
       "1              2.921319    12.783735    1.850048      0.293639     16.171896\n",
       "2              3.038696    13.022623    1.908270      0.316655     16.496910\n",
       "1             52.331852    12.654902    1.785889      0.340351     15.876081\n",
       "2              2.939575    13.047328    1.812695      0.354567     16.140940\n",
       "1              2.931685    13.695339    1.888933      0.325784     17.091923\n",
       "2              2.905485    12.825491    1.887194      0.337151     16.464405\n",
       "1              3.470058    12.600686    1.690859      0.275816     15.665549\n",
       "2              3.234261    14.885476    2.046081      0.574831     18.865957\n",
       "1              3.097044    12.835858    1.779412      0.300000     16.188978\n",
       "2              3.113313    12.904242    1.806452      0.287527     16.304647\n",
       "1             41.560074    12.060934    1.467850      0.200935     14.746906\n",
       "2              2.935695    12.173380    1.488147      0.210860     14.870617\n",
       "1              4.331007    12.717742    1.658917      0.377752     15.831400\n",
       "2              3.228000    13.144399    1.763345      0.414917     16.394499\n",
       "1              4.145880    12.476356    1.775733      0.307031     15.733659\n",
       "2              3.049400    12.726954    1.831512      0.330712     16.070793\n",
       "1              2.909785    12.890533    1.817403      0.313974     16.128195\n",
       "2              2.915018    13.094385    1.874219      0.337107     16.412281\n",
       "1              2.941266    13.073690    1.914098      0.322338     16.771259\n",
       "2              3.069315    13.340336    1.968144      0.334315     17.109434"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para apurar o resultado final basta fazer novamente um groupby (similar ao anterior) em cima do dataframe apurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.480346</td>\n",
       "      <td>12.687078</td>\n",
       "      <td>1.766031</td>\n",
       "      <td>0.306480</td>\n",
       "      <td>15.891758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.009232</td>\n",
       "      <td>12.940656</td>\n",
       "      <td>1.831276</td>\n",
       "      <td>0.334463</td>\n",
       "      <td>16.274137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trip_distance  fare_amount  tip_amount  tolls_amount  total_amount\n",
       "VendorID                                                                    \n",
       "1              8.480346    12.687078    1.766031      0.306480     15.891758\n",
       "2              3.009232    12.940656    1.831276      0.334463     16.274137"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('VendorID').mean()[['trip_distance','fare_amount','tip_amount','tolls_amount','total_amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations Resulting in a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para as operações de agregação recorre-se também a estruturas de dados que vão acumulando os valores agregados de cada chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo seguinte determinamos a percentagem de null values para cada uma das variáveis. Este é um processo um pouco mais trabalhoso dado que os valores obtidos de cada `chunk_df` vêem numa estrutura de pandas series. De qualquer das formas e uma vez que a estrutura se mantém em cada chunk (ou seja, é sempre o mesmo número de variáveis) podemos acumular os vários valores das series de cada dataframe na variável `ListOfValues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ListOfValues = np.zeros(len(column_names))\n",
    "ListOfValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "shape = 0\n",
    "ListOfValues = np.zeros(len(column_names))\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    shape+= chunk_df.shape[0]\n",
    "    \n",
    "    chunk_result = chunk_df.isna().sum()\n",
    "    ListOfIndexes = chunk_result.index\n",
    "    ListOfValues += chunk_result.values\n",
    "        \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente mostramos os resultados numa series final composta pelos índices e pelos valores acumulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                 0.0\n",
       "tpep_pickup_datetime     0.0\n",
       "tpep_dropoff_datetime    0.0\n",
       "passenger_count          0.0\n",
       "trip_distance            0.0\n",
       "payment_type             0.0\n",
       "fare_amount              0.0\n",
       "tip_amount               0.0\n",
       "tolls_amount             0.0\n",
       "total_amount             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.Series(ListOfValues,index=ListOfIndexes)\n",
    "series/shape* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value_Counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo seguinte determinamos os `value_counts` do `VendorID`. Neste caso concreto, a estrutura que se obtém a partir de cada chunk (uma série de dados) pode naturalmente incluir valores distintos. Assim, para acumular os valores de cada chunk recorremos a um dicionário. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count\n",
       "1    31392\n",
       "2     7060\n",
       "5     4947\n",
       "6     3441\n",
       "3     2148\n",
       "4     1011\n",
       "0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "dict_temp = {}\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    # chunk_result = chunk_df['VendorID'].value_counts()\n",
    "    chunk_result = chunk_df['passenger_count'].value_counts()\n",
    "    ListOfIndexes = chunk_result.index\n",
    "    ListOfValues = chunk_result.values\n",
    "    \n",
    "    for i in range(len(ListOfIndexes)):\n",
    "        dict_temp[ListOfIndexes[i]] = dict_temp.get(ListOfIndexes[i],0) + ListOfValues[i]\n",
    "        \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 6479710, 1: 5731242}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente poderíamos enviar estes dados para um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valuecounts_Keys</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6479710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5731242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valuecounts_Keys    Count\n",
       "0                 2  6479710\n",
       "1                 1  5731242"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuecounts_dict_df = pd.DataFrame([dict_temp]).T  # Let's tranpose it from row to column vector\n",
    "valuecounts_dict_df = valuecounts_dict_df.reset_index()  # Let's reset the index from the rating keys back to default\n",
    "valuecounts_dict_df.columns=['valuecounts_Keys','Count']\n",
    "valuecounts_dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma alternativa passar por obter a série de dados em cada chunk, transformá-los num dataframe, enviá-los para uma lista e no final de todos os chunks concatenar a lista de dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "result_temp = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df['VendorID'].value_counts()\n",
    "    \n",
    "    df = pd.DataFrame([chunk_result]).T  # Let's tranpose it from row to column vector\n",
    "    df = df.reset_index()  # Let's reset the index from the rating keys back to default\n",
    "    df.columns=['VendorID','Counts']\n",
    "\n",
    "    result_temp.append(df)\n",
    "           \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1\n",
    "\n",
    "df = pd.concat(result_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida podemos ver o dataframe concatenado. Naturalmente teremos ainda que fazer um groupby (ver abaixo) para agrupar os valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>311839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>270247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>229753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>267985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>232015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>267870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>232130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>273568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>226432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>436796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>63204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>446069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>489553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>302865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>197135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>267018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>232982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>263231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>236769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>264624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>235376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>266175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>233825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>389862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>110138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>490584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>485776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>255315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>244685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>267593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>232407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>265825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>111707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>99245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID  Counts\n",
       "0         2  311839\n",
       "1         1  188161\n",
       "0         2  270247\n",
       "1         1  229753\n",
       "0         2  267985\n",
       "1         1  232015\n",
       "0         2  267870\n",
       "1         1  232130\n",
       "0         2  273568\n",
       "1         1  226432\n",
       "0         2  436796\n",
       "1         1   63204\n",
       "0         2  446069\n",
       "1         1   53931\n",
       "0         2  489553\n",
       "1         1   10447\n",
       "0         2  302865\n",
       "1         1  197135\n",
       "0         2  265834\n",
       "1         1  234166\n",
       "0         2  267018\n",
       "1         1  232982\n",
       "0         2  263231\n",
       "1         1  236769\n",
       "0         2  265356\n",
       "1         1  234644\n",
       "0         2  264624\n",
       "1         1  235376\n",
       "0         2  265649\n",
       "1         1  234351\n",
       "0         2  266175\n",
       "1         1  233825\n",
       "0         1  389862\n",
       "1         2  110138\n",
       "0         1  490584\n",
       "1         2    9416\n",
       "0         1  485776\n",
       "1         2   14224\n",
       "0         1  255315\n",
       "1         2  244685\n",
       "0         2  267593\n",
       "1         1  232407\n",
       "0         2  265832\n",
       "1         1  234168\n",
       "0         2  265611\n",
       "1         1  234389\n",
       "0         2  265825\n",
       "1         1  234175\n",
       "0         2  111707\n",
       "1         1   99245"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte executa o groupby procedendo à soma dos valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID\n",
       "1    5731242\n",
       "2    6479710\n",
       "Name: Counts, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['VendorID'])['Counts'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No próximo exemplo pretendemos determinar a média do `trip_distance` por `VendorID`, razão pela qual vamos proceder a um `groupby`. O código abaixo mantém-se igual ao anterior, exceção feita à substituição do código de `value_counts` pelo código do `group_by`. De facto, o sistema continuará a gerar um pandas series. Só que ao invés do value_counts onde contabilizava valores, no caso da operação abaixo proceda à soma de valores médios, razão pela qual, posteriormente ainda vamos ter que dividir esses valores pelo número total de chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "dict_temp = {}\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df.groupby('VendorID').mean()['trip_distance']\n",
    "    ListOfIndexes = chunk_result.index\n",
    "    ListOfValues = chunk_result.values\n",
    "    \n",
    "    for i in range(len(ListOfIndexes)):\n",
    "        dict_temp[ListOfIndexes[i]] = dict_temp.get(ListOfIndexes[i],0) + ListOfValues[i]\n",
    "        \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como referido anteriormente, para apurarmos a média teremos ainda que dividir a soma dos valores operados pelo número de chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8.48034571647644, 2: 3.0092320346832278}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dict_temp:\n",
    "    dict_temp[key] = dict_temp[key]/chunk_no\n",
    "\n",
    "dict_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em alternativa podemos obter a série de dados em cada chunk, transformá-los num dataframe, enviá-los para uma lista e no final de todos os chunks concatenar a lista de dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk number = 0\n",
      "chunk number = 1\n",
      "chunk number = 2\n",
      "chunk number = 3\n",
      "chunk number = 4\n",
      "chunk number = 5\n",
      "chunk number = 6\n",
      "chunk number = 7\n",
      "chunk number = 8\n",
      "chunk number = 9\n",
      "chunk number = 10\n",
      "chunk number = 11\n",
      "chunk number = 12\n",
      "chunk number = 13\n",
      "chunk number = 14\n",
      "chunk number = 15\n",
      "chunk number = 16\n",
      "chunk number = 17\n",
      "chunk number = 18\n",
      "chunk number = 19\n",
      "chunk number = 20\n",
      "chunk number = 21\n",
      "chunk number = 22\n",
      "chunk number = 23\n",
      "chunk number = 24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size=500000\n",
    "chunk_no=0\n",
    "column_names = [\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"tolls_amount\", \"total_amount\"]\n",
    "\n",
    "result_temp = []\n",
    "\n",
    "path = \"data/yellow_tripdata_2016-03.csv\"\n",
    "#path = \"f:\\O meu disco\\data\\BigData\\yellow_taxi_data\\yellow_tripdata_2016-03.csv\"\n",
    "\n",
    "for chunk_df in pd.read_csv(path,chunksize=chunk_size,\n",
    "                    parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime'],\n",
    "                    usecols=column_names,\n",
    "                    dtype={\"VendorID\":\"int16\", \"passenger_count\": \"int8\", \"trip_distance\":\"float32\", \"payment_type\":\"int8\",  \"fare_amount\":\"float32\",\"tip_amount\":\"float32\",\"tolls_amount\":\"float32\",\"total_amount\":\"float32\"}):\n",
    "    \n",
    "    chunk_result = chunk_df.groupby('VendorID').mean()['trip_distance']\n",
    "    \n",
    "    df = pd.DataFrame([chunk_result]).T  # Let's tranpose it from row to column vector\n",
    "    df = df.reset_index()  # Let's reset the index from the rating keys back to default\n",
    "    df.columns=['VendorID','trip_distance']\n",
    "\n",
    "    result_temp.append(df)\n",
    "           \n",
    "    print(f\"chunk number = {chunk_no}\")\n",
    "    chunk_no+=1\n",
    "\n",
    "df = pd.concat(result_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De seguida podemos ver o dataframe concatenado. Naturalmente teremos ainda que fazer um groupby (ver abaixo) para agrupar os valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29.395535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.921303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.676330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.802897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.756580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.862911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.806111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.870971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.799309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.905119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.244994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.123266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.152014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.135735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.531933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.945799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.975181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.007746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.235002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.942349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.407313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.162585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.954083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.041197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.161613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.934990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.426266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.144284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.846411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.921319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.038696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>52.331852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.939575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.931685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.905485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.470058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.234261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.097044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.113313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.560074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.935695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.331007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.145880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.909785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.915018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.941266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.069315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID  trip_distance\n",
       "0         1      29.395535\n",
       "1         2       2.921303\n",
       "0         1       2.676330\n",
       "1         2       2.802897\n",
       "0         1       2.756580\n",
       "1         2       2.862911\n",
       "0         1       2.806111\n",
       "1         2       2.870971\n",
       "0         1       2.799309\n",
       "1         2       2.905119\n",
       "0         1       3.244994\n",
       "1         2       3.123266\n",
       "0         1       3.152014\n",
       "1         2       3.135735\n",
       "0         1       2.531933\n",
       "1         2       2.945799\n",
       "0         1      14.975181\n",
       "1         2       3.007746\n",
       "0         1       6.235002\n",
       "1         2       2.942349\n",
       "0         1       4.407313\n",
       "1         2       3.162585\n",
       "0         1       2.954083\n",
       "1         2       3.041197\n",
       "0         1       4.161613\n",
       "1         2       2.934990\n",
       "0         1       6.426266\n",
       "1         2       3.144284\n",
       "0         1       2.846411\n",
       "1         2       3.000887\n",
       "0         1       2.921319\n",
       "1         2       3.038696\n",
       "0         1      52.331852\n",
       "1         2       2.939575\n",
       "0         1       2.931685\n",
       "1         2       2.905485\n",
       "0         1       3.470058\n",
       "1         2       3.234261\n",
       "0         1       3.097044\n",
       "1         2       3.113313\n",
       "0         1      41.560074\n",
       "1         2       2.935695\n",
       "0         1       4.331007\n",
       "1         2       3.228000\n",
       "0         1       4.145880\n",
       "1         2       3.049400\n",
       "0         1       2.909785\n",
       "1         2       2.915018\n",
       "0         1       2.941266\n",
       "1         2       3.069315"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código seguinte executa o groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID\n",
       "1    8.480346\n",
       "2    3.009232\n",
       "Name: trip_distance, dtype: float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('VendorID').mean()['trip_distance']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
